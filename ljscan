#!/usr/bin/env python 

import cookurl
import urllib
import string
import os
import time
import xmllib
import sys

def makedict(attrs):
    attrdict = {}
    for attr in attrs:
        attrdict[string.lower(attr[0])] = attr[1]
    return attrdict                                 

transtable = string.maketrans("\240", " ")

def chomp(s):
    if s[-1:] == "\n":
        s = s[:-1]
    return s

def gettopdate(page):
    class myparser(xmllib.XMLParser):
        def __init__(self):
            xmllib.XMLParser.__init__(self)
            self.topdate = ""
            self.state = 0
        def unknown_starttag(self, tag, attrs):
            if tag == "pubDate" and self.state == 0:
                self.state = 1
        def unknown_endtag(self, tag):
            if tag == "pubDate" and self.state == 1:
                self.state = 2
        def handle_data(self, data):
            if self.state == 1:
                self.topdate = self.topdate + data
    p = myparser()
    p.feed(page)
    if p.state == 2:
        return p.topdate
    else:
        return None

# Read config file to get list of users.
ljusers = []
ljdir = os.environ["HOME"] + "/.ljscan/"
urltext = ""
f = open(ljdir + "config", "r")
while 1:
    s = f.readline()
    if s == "":
        break
    if s[:1] == "#":
        continue # skip commented lines
    while s[-1:] == "\r" or s[-1:] == "\n":
        s = s[:-1]
    ss = string.split(s)
    if len(ss) == 0:
        continue
    if s[:1] == "!":
        # Directive line.
        if string.lower(ss[0]) == "!urls":
            if string.lower(ss[1]) in ["yes", "y", "on", "1"]:
                urltext = "www.livejournal.com/users/"
            else:
                urltext = ""
        else:
            print "ljscan: config: unrecognised directive \""+ss[0]+"\""
        continue
    ljusers.append((ss[0], s))

# Get command-line options.
scan = 1
verbose = 0
args = []
for i in sys.argv[1:]:
    if i[0] == "-":
        if i == "-n":
            scan = 0
        elif i == "-v":
            verbose = verbose + 1
        else:
            print "ignoring unrecognised command-line argument:", i
    else:
        args.append(i)

# Filter list of users by command-line arguments.
if len(args) > 0:
    ljusers2 = []
    for i in ljusers:
        if i[0] in args:
            ljusers2.append(i)
            args.remove(i[0])
    for i in args:
        print "ignoring argument \""+i+"\": not in "+ljdir+"config"
    ljusers = ljusers2

template = "http://www.livejournal.com/users/%s/data/rss/"

now = time.time()
nowstr = str(now)

newlist = []
changelist = []
samelist = []
faillist = []
reportlist = []

# xmllib apparently doesn't approve of UTF-8 in its input. That's
# OK, because we don't actually need any of the UTF-8 encoded data
# - dates are in plain ASCII.
translator = \
string.maketrans(string.join(map(chr, range(128,256)), ""), 128 * ".")

# Fetch LJ login details, if available.
session = os.environ["HOME"] + "/.ljscan/ljsesscookies"
cookurl.loadcookies(session)

for t in ljusers:
    username, description = t
    if scan:
        url = template % username
        if verbose > 1:
            print "Fetching", url
        try:
            f = cookurl.urlopen(url)
            data = f.read()
            f.close()
        except IOError, e:
            print "Fetching", username+":", str(e)
            data = "" # this will already be treated as failure to retrieve
        data = string.translate(data, translator)
        print data
        d = gettopdate(data)

    # So username t has topmost date d. Compare this with the last
    # update and see if it's changed.
    try:
        f = open(ljdir + "date." + username, "r")
        olddate = chomp(f.readline())
        oldtime = chomp(f.readline())
        f.close()
    except IOError:
        olddate = ""
        oldtime = None

    if not scan:
        writeout = 0
        if oldtime == None:
            newlist.append((None, description))
        else:
            reportlist.append((float(oldtime), description))
    elif d == None:
        # Basic error handling: in case of failure to retrieve the
        # page, just add to the `failed retrieval' list.
        faillist.append((None, description))
        writeout = 0
    elif olddate == "":
        # The entry didn't previously exist. Add to the `new' list.
        newlist.append((now, description))
        writeout = 1
    elif olddate != d:
        # The entry has been modified. Add to the `changed' list.
        changelist.append((now, description))
        writeout = 1
    else:
        # The entry is unchanged. Add to the `unchanged' list.
        samelist.append((float(oldtime), description))
        writeout = 0

    if writeout:
        try:
            os.unlink(ljdir + "old." + username)
        except OSError:
            pass
        try:
            os.rename(ljdir + "date." + username, ljdir + "old." + username)
        except OSError:
            pass
        f = open(ljdir + "date." + username, "w")
        f.write(d + "\n" + nowstr + "\n")
        f.close()

# Right. Now sort the lists.
def alphabetical(a,b):
    if a[1] < b[1]: return -1
    if a[1] > b[1]: return +1
    return 0
def timealpha(a,b):
    if a[0] > b[0]: return -1
    if a[0] < b[0]: return +1
    if a[1] < b[1]: return -1
    if a[1] > b[1]: return +1
    return 0
newlist.sort(alphabetical)
changelist.sort(alphabetical)
samelist.sort(timealpha)
reportlist.sort(timealpha)
faillist.sort(alphabetical)

# And finally output everything.
def printout(a):
    if a[0] == None:
        ts = "                "
    else:
        ts = time.strftime("%Y-%m-%d %H:%M", time.localtime(a[0]))
    print ts, urltext + a[1]

if scan:
    if len(newlist):
        print "Journals not previously known to ljscan:"
        for i in newlist: printout(i)
    if len(changelist):
        print "Journals which have changed since the last scan:"
        for i in changelist: printout(i)
    if verbose:
        if len(samelist):
            print "Journals which are unchanged since the last scan:"
            for i in samelist: printout(i)
    elif len(newlist) == 0 and len(changelist) == 0:
        print "No new or changed journals found in this scan."
    if len(faillist):
        print "Journals which were not retrievable in this scan:"
        for i in faillist: printout(i)
else:
    if len(reportlist):
        print "Journals which have been scanned before:"
        for i in reportlist: printout(i)
    if len(newlist):
        print "Journals which have not been scanned before:"
        for i in newlist: printout(i)
